# Drone Video Anomaly Detection by Future Segmentation and Spatio-Temporal Relational Modeling

In traffic surveillance, accurate video anomaly detection is vital for public safety, yet environmental changes, occlusions, and visual obstructions pose significant challenges. In this research, we introduce **DAD-FSM**, an innovative drone-based video anomaly detection system that leverages a spatio-temporal relational cross-transformer to enhance the encoding of visual and temporal features for future segmentation. Additionally, we propose the motion-aware frame prediction loss function (MAFL) to improve the model's representation and the background and foreground separation of moving objects. Our method achieves state-of-the-art (SOTA) AUC scores of 68.13% on the UIT-ADrone dataset and 73.5% mAUC on the Drone-Anomaly dataset, surpassing previous methods by 2.68% and 5.71% respectively. These results demonstrate the potential of our model for broad use in traffic surveillance applications.

# DADFSM architectuture
![DADFSM](/figures/Overallmodel_alt.png)
